input_channel: 3

depth_multiple: 1.0
width_multiple: 1.0

backbone:
  # [repeat, module, args]
  [
    # Conv argument: [out_channel, kernel_size, stride, padding_size]
    # if padding_size is not given or null, the padding_size will be auto adjusted as padding='SAME' in TensorFlow
    [1, Conv, [16, 3, 2, null, 1, "HardSwish"]],
    # k t c SE HS s
    [1, InvertedResidualv3, [3, 1, 16, 0, 0, 1]],
    [1, InvertedResidualv3, [3, 4, 24, 0, 0, 2]], # 2-P2/4, 24 # stride 1 for cifar, 2 for others
    [1, InvertedResidualv3, [3, 3, 24, 0, 0, 1]],
    [1, InvertedResidualv3, [5, 3, 40, 1, 0, 2]], # 4-P3/8, 40
    [1, InvertedResidualv3, [5, 3, 40, 1, 0, 1]],
    [1, InvertedResidualv3, [5, 3, 40, 1, 0, 1]],
    [1, InvertedResidualv3, [3, 6, 80, 0, 1, 2]], # 7-P4/16, 80
    [1, InvertedResidualv3, [3, 2.5, 80, 0, 1, 1]],
    [1, InvertedResidualv3, [3, 2.3, 80, 0, 1, 1]],
    [1, InvertedResidualv3, [3, 2.3, 80, 0, 1, 1]],
    [1, InvertedResidualv3, [3, 6, 112, 1, 1, 1]],
    [1, InvertedResidualv3, [3, 6, 112, 1, 1, 1]], # 12 -P5/32, 112
    [1, InvertedResidualv3, [5, 6, 160, 1, 1, 2]],
    [1, InvertedResidualv3, [5, 6, 160, 1, 1, 1]],
    [1, InvertedResidualv3, [5, 6, 160, 1, 1, 1]],
    [1, Conv, [960, 1, 1]],
    [1, GlobalAvgPool, []],
    [1, Conv, [1280, 1, 1]],
    [1, Flatten, []],
    [1, Linear, [6]],
  ]
############### FEATURES ###############
# ConvBNActivation(
#   (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
#   (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#   (2): Hardswish()
# )
# InvertedResidual(
#   (block): Sequential(
#     (0): ConvBNActivation(
#       (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)
#       (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): ReLU(inplace=True)
#     )
#     (1): ConvBNActivation(
#       (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Identity()
#     )
#   )
# )
# InvertedResidual(
#   (block): Sequential(
#     (0): ConvBNActivation(
#       (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): ReLU(inplace=True)
#     )
#     (1): ConvBNActivation(
#       (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)
#       (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): ReLU(inplace=True)
#     )
#     (2): ConvBNActivation(
#       (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Identity()
#     )
#   )
# )
# InvertedResidual(
#   (block): Sequential(
#     (0): ConvBNActivation(
#       (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): ReLU(inplace=True)
#     )
#     (1): ConvBNActivation(
#       (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)
#       (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): ReLU(inplace=True)
#     )
#     (2): ConvBNActivation(
#       (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Identity()
#     )
#   )
# )
# InvertedResidual(
#   (block): Sequential(
#     (0): ConvBNActivation(
#       (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): ReLU(inplace=True)
#     )
#     (1): ConvBNActivation(
#       (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)
#       (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): ReLU(inplace=True)
#     )
#     (2): SqueezeExcitation(
#       (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))
#       (relu): ReLU(inplace=True)
#       (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))
#     )
#     (3): ConvBNActivation(
#       (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Identity()
#     )
#   )
# )
# InvertedResidual(
#   (block): Sequential(
#     (0): ConvBNActivation(
#       (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): ReLU(inplace=True)
#     )
#     (1): ConvBNActivation(
#       (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)
#       (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): ReLU(inplace=True)
#     )
#     (2): SqueezeExcitation(
#       (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))
#       (relu): ReLU(inplace=True)
#       (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))
#     )
#     (3): ConvBNActivation(
#       (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Identity()
#     )
#   )
# )
# InvertedResidual(
#   (block): Sequential(
#     (0): ConvBNActivation(
#       (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): ReLU(inplace=True)
#     )
#     (1): ConvBNActivation(
#       (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)
#       (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): ReLU(inplace=True)
#     )
#     (2): SqueezeExcitation(
#       (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))
#       (relu): ReLU(inplace=True)
#       (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))
#     )
#     (3): ConvBNActivation(
#       (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Identity()
#     )
#   )
# )
# InvertedResidual(
#   (block): Sequential(
#     (0): ConvBNActivation(
#       (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Hardswish()
#     )
#     (1): ConvBNActivation(
#       (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)
#       (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Hardswish()
#     )
#     (2): ConvBNActivation(
#       (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Identity()
#     )
#   )
# )
# InvertedResidual(
#   (block): Sequential(
#     (0): ConvBNActivation(
#       (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Hardswish()
#     )
#     (1): ConvBNActivation(
#       (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)
#       (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Hardswish()
#     )
#     (2): ConvBNActivation(
#       (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Identity()
#     )
#   )
# )
# InvertedResidual(
#   (block): Sequential(
#     (0): ConvBNActivation(
#       (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Hardswish()
#     )
#     (1): ConvBNActivation(
#       (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)
#       (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Hardswish()
#     )
#     (2): ConvBNActivation(
#       (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Identity()
#     )
#   )
# )
# InvertedResidual(
#   (block): Sequential(
#     (0): ConvBNActivation(
#       (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Hardswish()
#     )
#     (1): ConvBNActivation(
#       (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)
#       (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Hardswish()
#     )
#     (2): ConvBNActivation(
#       (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Identity()
#     )
#   )
# )
# InvertedResidual(
#   (block): Sequential(
#     (0): ConvBNActivation(
#       (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Hardswish()
#     )
#     (1): ConvBNActivation(
#       (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)
#       (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Hardswish()
#     )
#     (2): SqueezeExcitation(
#       (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))
#       (relu): ReLU(inplace=True)
#       (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))
#     )
#     (3): ConvBNActivation(
#       (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Identity()
#     )
#   )
# )
# InvertedResidual(
#   (block): Sequential(
#     (0): ConvBNActivation(
#       (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Hardswish()
#     )
#     (1): ConvBNActivation(
#       (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)
#       (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Hardswish()
#     )
#     (2): SqueezeExcitation(
#       (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))
#       (relu): ReLU(inplace=True)
#       (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))
#     )
#     (3): ConvBNActivation(
#       (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Identity()
#     )
#   )
# )
# InvertedResidual(
#   (block): Sequential(
#     (0): ConvBNActivation(
#       (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Hardswish()
#     )
#     (1): ConvBNActivation(
#       (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)
#       (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Hardswish()
#     )
#     (2): SqueezeExcitation(
#       (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))
#       (relu): ReLU(inplace=True)
#       (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))
#     )
#     (3): ConvBNActivation(
#       (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Identity()
#     )
#   )
# )
# InvertedResidual(
#   (block): Sequential(
#     (0): ConvBNActivation(
#       (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Hardswish()
#     )
#     (1): ConvBNActivation(
#       (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)
#       (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Hardswish()
#     )
#     (2): SqueezeExcitation(
#       (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))
#       (relu): ReLU(inplace=True)
#       (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))
#     )
#     (3): ConvBNActivation(
#       (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Identity()
#     )
#   )
# )
# InvertedResidual(
#   (block): Sequential(
#     (0): ConvBNActivation(
#       (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Hardswish()
#     )
#     (1): ConvBNActivation(
#       (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)
#       (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Hardswish()
#     )
#     (2): SqueezeExcitation(
#       (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))
#       (relu): ReLU(inplace=True)
#       (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))
#     )
#     (3): ConvBNActivation(
#       (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
#       (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#       (2): Identity()
#     )
#   )
# )
# ConvBNActivation(
#   (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)
#   (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)
#   (2): Hardswish()
# )

# ??? Question: Where is 960 to 1280 convolution on torchvision???
